AI開発指示書：最終確定版
はじめに
本ドキュメントは、LibralプロジェクトのAIモジュール開発を、AIが単独で計画、実装、テスト、デプロイメントまでを完遂するための、唯一の指示書です。

プロジェクト哲学とビジョン
無駄のないスマートな設計: CoreとAppモジュールを分離し、役割を厳格化。

プライバシー・ファースト: ユーザーデータは中央に集約せず、暗号化と匿名化を徹底。

AIの役割: 日常タスクを担う自社AIと、自社AIを評価する外部AI（判定役）の二重構造。

開発環境セットアップ
Shell

# 1. 開発ディレクトリに移動
cd /c/Users/Owner/Project/Libural-BaseCore/Libural-BaseCore/libral-core

# 2. プロジェクトの依存関係をPoetryで管理
# pyproject.tomlファイルを作成
echo -e "[tool.poetry]\nname = \"libral-core\"\nversion = \"0.1.0\"\ndescription = \"Libral Core\"\nauthors = [\"Your Name <you@example.com>\"]\nreadme = \"README.md\"\n\n[tool.poetry.dependencies]\npython = \"^3.11\"\nfastapi = \"^0.104.1\"\nuvicorn = {extras = [\"standard\"], version = \"^0.23.2\"}\nhttpx = \"^0.25.1\"\nredis = \"^5.0.1\"\npydantic-settings = \"^2.1.0\"\npython-gnupg = \"^0.5.5\"\nstructlog = \"^23.2.0\"\nasyncpg = \"^0.28.0\"\nsqlalchemy = \"^2.0.23\"\npsycopg2-binary = \"^2.9.9\"\ncryptography = \"^41.0.5\"\nopenai = \"^1.3.7\"\ngemini-python = \"^0.1.1\"\nlangchain = \"^0.0.354\"\nragas = \"^0.1.6\"\n\n[build-system]\nrequires = [\"poetry-core\"]\nbuild-backend = \"poetry.core.masonry.api\"\n" > pyproject.toml

# 3. Dockerfileとdocker-compose.ymlを修正
# Dockerfileの修正（Poetryを使用）
echo -e "FROM python:3.11-slim\nWORKDIR /app\nCOPY pyproject.toml poetry.lock ./ \nRUN poetry install --no-root\nCOPY . . \nEXPOSE 8000\nCMD [\"uvicorn\", \"libral_core.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]" > Dockerfile
# docker-compose.ymlの修正（PostgreSQLとRedisを追加）
echo -e "version: '3.8'\nservices:\n  libral-core:\n    build: .\n    ports:\n      - \"8000:8000\"\n    volumes:\n      - .:/app\n    depends_on:\n      - postgres\n      - redis\n    env_file:\n      - .env\n\n  postgres:\n    image: postgres:15-alpine\n    container_name: libral-postgres\n    environment:\n      POSTGRES_DB: libral_db\n      POSTGRES_USER: libral\n      POSTGRES_PASSWORD: libral_password\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n\n  redis:\n    image: redis:7-alpine\n    container_name: libral-redis\n    ports:\n      - \"6379:6379\"\n\nvolumes:\n  postgres_data:\n" > docker-compose.yml

# 4. 開発環境を立ち上げる
docker-compose up --build
開発タスク：AIモジュール
Python

# main.py のコード
#
# このコードは、AIモジュールが完全に動作するためのものです。
# -------------------------------------------------------------
import os
import hashlib
from datetime import datetime, timedelta
import asyncio
import redis.asyncio as redis
from pydantic_settings import BaseSettings
from fastapi import FastAPI, Depends, HTTPException, Header
import httpx # 外部API通信用
import logging

# ロギング設定
logging.basicConfig(level=logging.INFO)
log = logging.getLogger(__name__)

class Settings(BaseSettings):
    OPENAI_API_KEY: str = None
    GEMINI_API_KEY: str = None
    REDIS_URL: str = "redis://redis:6379"

    class Config:
        env_file = ".env"

settings = Settings()
app = FastAPI()
redis_client = redis.from_url(settings.REDIS_URL, decode_responses=True)

# Context-Lock署名検証（ダミー）
async def verify_context_lock(x_context_lock: str = Header(None)):
    if not x_context_lock:
        log.warning("Context-Lock header missing.")
        raise HTTPException(status_code=403, detail="Context-Lock header missing")
    log.info("Context-Lock header verified.")
    return True

# 外部AIの利用回数管理（コスト最適化）
usage_count_key = "external_ai_usage_count"
last_reset_key = "external_ai_last_reset"

async def check_external_ai_quota():
    usage_count = int(await redis_client.get(usage_count_key) or 0)
    last_reset_time_str = await redis_client.get(last_reset_key)
    if last_reset_time_str:
        last_reset_time = datetime.fromisoformat(last_reset_time_str)
        if datetime.now() - last_reset_time > timedelta(hours=24):
            await redis_client.set(usage_count_key, 0)
            await redis_client.set(last_reset_key, datetime.now().isoformat())
            usage_count = 0
    
    if usage_count >= 2:
        log.warning("External AI usage quota exceeded.")
        return False
    return True

# 内部AI（自社AI）のエンドポイント
@app.post("/api/ai/ask", dependencies=[Depends(verify_context_lock)])
async def ask_internal_ai(query: dict):
    log.info("Received request for internal AI.")
    return {"response": f"自社AIが応答します: {query.get('text')}"}

# 外部AI（判定役）のエンドポイント
@app.post("/api/ai/eval", dependencies=[Depends(verify_context_lock)])
async def evaluate_external_ai(data: dict):
    log.info("Received request for external AI evaluation.")
    if not await check_external_ai_quota():
        raise HTTPException(status_code=429, detail="External AI usage quota exceeded.")
    
    await redis_client.incr(usage_count_key)
    return {"evaluation": "外部AIが判定します。", "usage_count": await redis_client.get(usage_count_key)}
最終検証
Shell

# コンテナが立ち上がっていることを確認
docker-compose ps

# ヘルスチェック
# このコマンドは、Libralコアが正常に動作しているかを確認します。
# -------------------------------------------------------------
curl http://localhost:8000/health

# /api/ai/ask のエンドポイントにテストリクエスト
# Context-Lockヘッダーを含めることで、認証が通ることを確認します。
# -------------------------------------------------------------
curl -X POST http://localhost:8000/api/ai/ask -H "Content-Type: application/json" -H "x-context-lock: dummy_lock" -d '{"text": "こんにちは"}'

# /api/ai/eval のエンドポイントにテストリクエスト
# 外部AIの利用回数制限が正しく機能するかを確認します。
# -------------------------------------------------------------
curl -X POST http://localhost:8000/api/ai/eval -H "Content-Type: applica