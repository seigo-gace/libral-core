"""
Libral AI Module - Standalone FastAPI Application
Revolutionary Dual-AI System with Privacy-First Architecture

This is the main entry point for the AI module when running as an independent service.
å®Œå…¨ã«ç‹¬ç«‹ã—ãŸAIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ã—ã¦ã®FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
"""

import os
from contextlib import asynccontextmanager

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
import structlog
import uvicorn

from .router import router
from .schemas import AIConfig
from .service import LibralAI

# Configure structured logging
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger(__name__)

# Global AI service instance
ai_service = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan management"""
    global ai_service
    
    # Startup
    logger.info(
        "Libral AI Module starting up",
        version="1.0.0",
        architecture="Revolutionary Dual-AI System",
        features=[
            "å†…éƒ¨AI (è‡ªç¤¾AI) - Privacy-First Daily Tasks",
            "å¤–éƒ¨AI (åˆ¤å®šå½¹) - Quality Evaluation System", 
            "Context-Lock Security Verification",
            "Usage Quota Management (2 calls/24h for External AI)",
            "Redis-based Caching and Usage Tracking",
            "Complete Privacy Protection"
        ]
    )
    
    # Initialize AI service
    redis_url = os.getenv("REDIS_URL", "redis://localhost:6379")
    config = AIConfig(
        openai_api_key=os.getenv("OPENAI_API_KEY"),
        gemini_api_key=os.getenv("GEMINI_API_KEY"),
        anthropic_api_key=os.getenv("ANTHROPIC_API_KEY")
    )
    
    ai_service = LibralAI(config=config, redis_url=redis_url)
    
    logger.info(
        "Libral AI Module startup completed",
        components=[
            "Internal AI (è‡ªç¤¾AI)",
            "External AI (åˆ¤å®šå½¹)",
            "Context-Lock Verifier", 
            "Usage Manager",
            "Redis Cache"
        ],
        security_features=[
            "Context-Lock Required",
            "Privacy-First Design",
            "Usage Quota Protection",
            "Cost Optimization"
        ]
    )
    
    yield
    
    # Shutdown
    logger.info("Libral AI Module shutting down")
    if ai_service and hasattr(ai_service, 'redis_client'):
        await ai_service.redis_client.close()

# Create FastAPI application
app = FastAPI(
    title="Libral AI Module - Revolutionary Dual-AI System",
    description="""
    ## ğŸ¤– Libral AI Module - ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼å„ªå…ˆã®é©å‘½çš„åŒAI ã‚·ã‚¹ãƒ†ãƒ 
    
    ### âœ¨ é©å‘½çš„ãƒ‡ãƒ¥ã‚¢ãƒ«AIã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
    
    #### ğŸ  å†…éƒ¨AIï¼ˆè‡ªç¤¾AIï¼‰- Privacy-First Daily Tasks
    - **ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼å„ªå…ˆè¨­è¨ˆ**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä¸­å¤®é›†ç´„ã›ãšå®Œå…¨æš—å·åŒ–
    - **æ—¥å¸¸ã‚¿ã‚¹ã‚¯å¯¾å¿œ**: ä¸€èˆ¬çš„ãªã‚¯ã‚¨ãƒªã‹ã‚‰æŠ€è¡“çš„è³ªå•ã¾ã§å¹…åºƒãã‚µãƒãƒ¼ãƒˆ
    - **é«˜é€Ÿå¿œç­”**: å¹³å‡100msä»¥ä¸‹ã®å¿œç­”æ™‚é–“
    - **ç„¡åˆ¶é™åˆ©ç”¨**: 1æ—¥æœ€å¤§1000å›ã¾ã§ç„¡æ–™åˆ©ç”¨å¯èƒ½
    - **Context-Lockèªè¨¼**: å…¨ã¦ã®æ“ä½œã§ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£èªè¨¼å¿…é ˆ
    
    #### ğŸ¯ å¤–éƒ¨AIï¼ˆåˆ¤å®šå½¹ï¼‰- Quality Evaluation System  
    - **å“è³ªä¿è¨¼ã‚·ã‚¹ãƒ†ãƒ **: å†…éƒ¨AIã®å¿œç­”å“è³ªã‚’å¤–éƒ¨AIãŒè©•ä¾¡
    - **ã‚³ã‚¹ãƒˆæœ€é©åŒ–**: 1æ—¥2å›ã¾ã§é™å®šåˆ©ç”¨ã§è²»ç”¨ã‚’æŠ‘åˆ¶
    - **åŒ…æ‹¬çš„è©•ä¾¡**: æ­£ç¢ºæ€§ã€é–¢é€£æ€§ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼éµå®ˆãªã©å¤šè§’çš„è©•ä¾¡
    - **æ”¹å–„ææ¡ˆ**: å…·ä½“çš„ãªæ”¹å–„æ¡ˆã¨ä»£æ›¿å¿œç­”ã®æä¾›
    - **ä½¿ç”¨é‡ç®¡ç†**: Redis-basedã‚¯ã‚©ãƒ¼ã‚¿ã‚·ã‚¹ãƒ†ãƒ ã§åˆ©ç”¨åˆ¶é™ã‚’å³æ ¼ç®¡ç†
    
    ### ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ & ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼æ©Ÿèƒ½
    
    - **Context-Lockç½²å**: å…¨APIæ“ä½œã§ãƒ‡ã‚¸ã‚¿ãƒ«ç½²åã«ã‚ˆã‚‹èªè¨¼
    - **æš—å·åŒ–é€šä¿¡**: ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰æš—å·åŒ–ã§å®Œå…¨ç§˜åŒ¿æ€§ç¢ºä¿
    - **å€‹äººæƒ…å ±é™¤å»**: PIIè‡ªå‹•æ¤œå‡ºãƒ»é™¤å»ã‚·ã‚¹ãƒ†ãƒ 
    - **24æ™‚é–“è‡ªå‹•å‰Šé™¤**: ãƒ­ã‚°ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®è‡ªå‹•æ¶ˆå»
    - **åˆ†æ•£ãƒ­ã‚°**: Telegramå€‹äººã‚µãƒ¼ãƒãƒ¼ã¸ã®ãƒ­ã‚°åˆ†æ•£ä¿å­˜
    
    ### ğŸ’° ã‚³ã‚¹ãƒˆç®¡ç†æ©Ÿèƒ½
    
    - **ã‚¹ãƒãƒ¼ãƒˆã‚¯ã‚©ãƒ¼ã‚¿**: AIç¨®åˆ¥ã”ã¨ã®åˆ©ç”¨åˆ¶é™ï¼ˆå†…éƒ¨AI: 1000/æ—¥ã€å¤–éƒ¨AI: 2/æ—¥ï¼‰
    - **è‡ªå‹•ãƒªã‚»ãƒƒãƒˆ**: 24æ™‚é–“ã”ã¨ã®åˆ©ç”¨ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼è‡ªå‹•ãƒªã‚»ãƒƒãƒˆ
    - **ã‚³ã‚¹ãƒˆè¿½è·¡**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã®åˆ©ç”¨æ–™é‡‘è¨ˆç®—ãƒ»è¡¨ç¤º
    - **åˆ©ç”¨çµ±è¨ˆ**: è©³ç´°ãªä½¿ç”¨çŠ¶æ³ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
    
    ### ğŸš€ ä¸»è¦ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    
    #### Internal AI (è‡ªç¤¾AI)
    - `POST /api/ai/ask` - é«˜æ©Ÿèƒ½AIå•ã„åˆã‚ã›ï¼ˆå®Œå…¨ã‚¹ã‚­ãƒ¼ãƒå¯¾å¿œï¼‰
    - `POST /api/ai/ask/simple` - ã‚·ãƒ³ãƒ—ãƒ«AIå•ã„åˆã‚ã›ï¼ˆäº’æ›æ€§é‡è¦–ï¼‰
    
    #### External AI (åˆ¤å®šå½¹)
    - `POST /api/ai/eval` - AIå¿œç­”å“è³ªè©•ä¾¡ï¼ˆå®Œå…¨è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ï¼‰
    - `POST /api/ai/eval/simple` - ã‚·ãƒ³ãƒ—ãƒ«è©•ä¾¡ï¼ˆåŸºæœ¬æ©Ÿèƒ½ï¼‰
    
    #### Usage Management
    - `GET /api/ai/usage/stats` - åˆ©ç”¨çµ±è¨ˆæƒ…å ±
    - `GET /api/ai/quota/status` - ã‚¯ã‚©ãƒ¼ã‚¿çŠ¶æ³ç¢ºèª
    
    #### Health & Monitoring
    - `GET /api/ai/health` - ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯
    - `GET /api/ai/metrics` - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
    
    ### ğŸ› ï¸ é–‹ç™ºä»•æ§˜
    
    - **Framework**: FastAPI + Pydantic V2
    - **Caching**: Redis with automatic expiration
    - **Logging**: Structured logging with privacy protection
    - **Authentication**: Context-Lock signature verification
    - **Database**: Redis for quota/cache, no persistent user data
    - **Architecture**: Microservice-ready, container-friendly
    
    ### ğŸ“‹ ä½¿ç”¨ä¾‹
    
    ```bash
    # å†…éƒ¨AIå•ã„åˆã‚ã›
    curl -X POST "http://localhost:8001/api/ai/ask/simple" \\
         -H "Content-Type: application/json" \\
         -H "x-context-lock: dummy_signature_12345678901234567890" \\
         -H "Authorization: Bearer access_token_user123" \\
         -d '{"text": "ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ã®ä»•çµ„ã¿ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„"}'
    
    # å¤–éƒ¨AIè©•ä¾¡
    curl -X POST "http://localhost:8001/api/ai/eval/simple" \\
         -H "Content-Type: application/json" \\
         -H "x-context-lock: dummy_signature_12345678901234567890" \\
         -H "Authorization: Bearer access_token_user123" \\
         -d '{}'
    
    # åˆ©ç”¨çŠ¶æ³ç¢ºèª
    curl -X GET "http://localhost:8001/api/ai/quota/status" \\
         -H "Authorization: Bearer access_token_user123"
    ```
    
    ğŸŒŸ **Libral AI Module**: ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã‚’æœ€å„ªå…ˆã«ã—ãŸé©å‘½çš„ãªAIã‚µãƒ¼ãƒ“ã‚¹ã‚’ãŠè©¦ã—ãã ã•ã„ï¼
    """,
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json",
    lifespan=lifespan
)

# Security Middleware
app.add_middleware(
    TrustedHostMiddleware,
    allowed_hosts=["*"]  # In production, restrict to specific domains
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # In production, restrict to specific origins
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["*"],
)

# Include the AI router
app.include_router(router)

# Health check endpoint for the standalone app
@app.get("/health")
async def health_check():
    """Standalone AI module health check"""
    return {
        "status": "healthy",
        "service": "Libral AI Module",
        "version": "1.0.0",
        "architecture": "Revolutionary Dual-AI System",
        "components": {
            "internal_ai": "healthy",
            "external_ai": "healthy",
            "context_lock_verifier": "healthy",
            "usage_manager": "healthy",
            "redis_cache": "healthy"
        },
        "capabilities": [
            "å†…éƒ¨AI (è‡ªç¤¾AI) - Privacy-First Responses",
            "å¤–éƒ¨AI (åˆ¤å®šå½¹) - Quality Evaluation",
            "Context-Lock Security Verification",
            "Smart Usage Quota Management",
            "Cost Optimization (2 calls/24h limit)",
            "Redis-based Caching System",
            "Complete Privacy Protection"
        ]
    }

# System information endpoint
@app.get("/info")
async def system_info():
    """Get AI module system information"""
    return {
        "libral_ai_module": {
            "name": "Libral AI Module",
            "version": "1.0.0",
            "architecture": "Revolutionary Dual-AI System",
            "status": "operational"
        },
        "ai_systems": {
            "internal_ai": {
                "name": "å†…éƒ¨AI (è‡ªç¤¾AI)",
                "description": "Privacy-first AI for daily tasks",
                "daily_limit": 1000,
                "cost_per_query": 0.0
            },
            "external_ai": {
                "name": "å¤–éƒ¨AI (åˆ¤å®šå½¹)",
                "description": "Quality evaluation system",
                "daily_limit": 2,
                "cost_per_evaluation": 0.01
            }
        },
        "security_features": [
            "Context-Lock signature verification",
            "End-to-end encryption",
            "Automatic PII removal",
            "24-hour auto-delete",
            "Distributed logging"
        ],
        "privacy_model": [
            "No central user data storage",
            "Telegram personal log servers",
            "Complete data sovereignty",
            "Privacy-preserving AI processing",
            "Encrypted communication channels"
        ]
    }

# Configuration endpoint  
@app.get("/config")
async def get_configuration():
    """Get AI module configuration"""
    return {
        "ai_configuration": {
            "internal_ai": {
                "model": "libral-internal-v1",
                "response_time_target_ms": 100,
                "daily_limit": 1000,
                "cost_model": "free"
            },
            "external_ai": {
                "providers": ["openai", "gemini", "anthropic"],
                "default_model": "gpt-4",
                "daily_limit": 2,
                "hourly_limit": 1,
                "cost_per_call": 0.01
            },
            "security": {
                "context_lock_required": True,
                "encryption_enabled": True,
                "pii_removal": True,
                "auto_delete_hours": 24
            },
            "performance": {
                "max_concurrent_requests": 10,
                "timeout_seconds": 30,
                "cache_ttl_hours": 24,
                "redis_enabled": True
            }
        }
    }

# Development server configuration
if __name__ == "__main__":
    # Get configuration from environment
    host = os.getenv("AI_HOST", "0.0.0.0")
    port = int(os.getenv("AI_PORT", "8001"))
    reload = os.getenv("AI_RELOAD", "true").lower() == "true"
    log_level = os.getenv("AI_LOG_LEVEL", "info").lower()
    
    print(f"""
ğŸ¤– Libral AI Module - Revolutionary Dual-AI System Starting...

ğŸ  å†…éƒ¨AI (è‡ªç¤¾AI): Privacy-first daily task processing
ğŸ¯ å¤–éƒ¨AI (åˆ¤å®šå½¹): Quality evaluation and improvement system
ğŸ”’ Security: Context-Lock verification required
ğŸ’° Cost Management: Smart quota system (2 external calls/24h)
ğŸ“Š Monitoring: Complete usage statistics and health checks

Server Configuration:
- Host: {host}
- Port: {port}
- Reload: {reload}
- Log Level: {log_level}

API Documentation: http://{host}:{port}/docs
Health Check: http://{host}:{port}/health
System Info: http://{host}:{port}/info
""")
    
    uvicorn.run(
        "libral_core.modules.ai.app:app",
        host=host,
        port=port,
        reload=reload,
        log_level=log_level
    )